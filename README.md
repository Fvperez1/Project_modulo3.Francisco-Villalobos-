# Project_modulo3.Francisco-Villalobos-


EDAğŸ“Œ

Unificamos todos los Data Set de los diamantes hasta conseguir tener el dataset con todas las features a tener en cuenta para el precio del diamanta.

Una vez unificados estos Data Set, procedemos a realizar el Eda, donde observamos que las features mÃ¡s relacionadas con el precio son las features X, Y e Z, teniendo en cuenta esto, multiplicamos estas features y nos da el volumen del diamante. 

El precio del diamante tiene relacaciÃ³n con el volumen, por lo tanto, cuanto mÃ¡s caro es el diamante, es porque su tamaÃ±o es mayor.

Las otras features que encontramos en el Data set, tienen menos incidencia sobre el precio del diamante, estas features son: la ciudad, el color, la claridad, y el corte.


Best Model ğŸ’»

Predicciones_Model_1

El mejor RMSE en Kaggle: 568,131 / Notebook: 597,081
DescripciÃ³n del modelo:

Paso 1: Creamos la nueva vfeature Volumen, multiplicado las features relacionadas con el tamaÃ±o.

Paso 2: Separamos el precio del resto de features.

Paso 3: Separamos las features, "carat	depth	table	x	y	z	total"

Paso 4: Escalamos las features numÃ©ricas utilizando el StandardScaler, y lo pasamos de nuevo a Dataframe.

Paso 5: Convertirmos las features cualitativas a numericas para posteriormente escalarlas de nuevo con el StandardScaler.

Paso 5: Convertirmos las features cualitativas a numericas para ello, le damos peso o valores a estas features. Posteriormente las escalamos con StandardScaler.

Paso 6: Una vez que tenemos nuestros Dataframes los unimos con un merge y entrenamos el modelo sobre ese Dataframe.

Paso 7: Para entrenarlo aplicamos al Dataframe el train_test_split para poder poder trabajar con el X_train y aplicarlo a X_test.

Paso 8: Aplicamos el RandomForestRegressor, el modelo que mejor RMSE nos ha dado. Para los parÃ¡metros hemos utilizado parÃ¡mtros tipo.

Paso 9: Posteriormente aplicamos el mismo trabajo el al dataset para el que queremos predecir.


Predicciones_Model_2


El mejor RMSE en notebook: 571,44/Kaggle: 568,42

DescripciÃ³n del modelo:



Paso 1: Creamos la nueva vfeature Volumen, multiplicado las features relacionadas con el tamaÃ±o.

Paso 2: Separamos el precio del resto de features.

Paso 3: Escalamos las variables nÃºmericas, con StandardScaler.

Paso 2: Convertimos las variables categÃ³ricas a numÃ©ricas, utilizando LabelEncoder()

Paso 3: Escalamos las variables una vez convertidas a numÃ©ricas

Paso 6: Una vez que tenemos nuestros Dataframes los unimos con un merge y entrenamos el modelo sobre ese Dataframe.

Paso 7: Para entrenarlo aplicamos al Dataframe el train_test_split para poder poder trabajar con el X_train y aplicarlo a X_test.

Paso 8: Aplicamos el RandomForestRegressor, el modelo que mejor RMSE nos ha dado. Para los parÃ¡metros hemos utilizado parÃ¡mtros tipo.

Paso 9: Posteriormente aplicamos el mismo trabajo el al dataset para el que queremos predecir.



Analysis âœ’ï¸


Despues de la realizaciÃ³n de multiples anÃ¡lis, que cuanto mÃ¡s datos mejor, es decir, el modelo aprende las features y de este modo puede predecir mejor los precios de los diamantes en funciÃ³n de dichas features. 


Entrenando el modelo con diferentes mÃ©todos como: (linear-regression, Random_forest, Catboosting)
He elegido el andmForest nos da el RMSE mÃ¡s bajo, y la preddiciÃ³n se ajusta mÃ¡s a nuestra necesidad debido a nuestras features.



Librery ğŸ“š

import numpy as np
import pandas as pd
from sklearn.preprocessing import RobustScaler, StandardScaler
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestRegressor


Folder structure ğŸ’¾
â””â”€â”€ PROJECT_M3
    â”œâ”€â”€Predicciones_Model_1
    â”œâ”€â”€Predicciones_Model_1
    â”œâ”€â”€DataSet
    â”œâ”€â”€ Link.txt
    â”œâ”€â”€ README.md
    â”œâ”€â”€ .ipynb_checkpoints
    â”œâ”€â”€ .DS_Store


Contact info  ğŸ’Œ 

    â”œâ”€â”€ Email: fco.villalobos.perez@gmail.com
    â”œâ”€â”€ MÃ³vil: 659.895.049

![image](https://user-images.githubusercontent.com/102686594/194706870-bcc596f0-b06f-40ca-9931-01b5ee0b8cbb.png)

